{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extended Modeling - Binary Naive Bayes & Logistic Regression\n",
    "To solve create less imbalance, we will change the problem to a binary classification problem.  We are now trying to classify the reviews as positive (4 or 5 stars) or not positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.functions import col, split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import json\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    " def report(fitted):   \n",
    "    ypred = fitted.predict(Xtest)\n",
    "\n",
    "    print(\"[Training Classification Report:]\")\n",
    "    print(classification_report(ytrain, fitted.predict(Xtrain)))\n",
    "    print('Training Accuracy: ',accuracy_score(fitted.predict(Xtrain), ytrain))\n",
    "    print('')\n",
    "    print(\"[Test Classification Report:]\")\n",
    "    print(classification_report(ytest, ypred))\n",
    "    print('Test Accuracy: ', accuracy_score(ypred, ytest))\n",
    "\n",
    "    yprobs = fitted.predict_proba(Xtest)[:,1]\n",
    "    fpr, tpr, threshold = roc_curve(ytest,  yprobs)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    print('')\n",
    "    print('AUC: ', roc_auc)\n",
    "    print('')\n",
    "    print('Log loss: ', log_loss(ytest, yprobs))\n",
    "    \n",
    "    return ypred, yprobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function BufferedReader.close>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infile = open('../SavedFiles/fastFood_eng.pkl', 'rb')\n",
    "fastFood = pickle.load(infile)\n",
    "infile.close"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Classification\n",
    "We will define 4- and 5-star reviews as \"positive\" and 1-, 2-. and 3-star reviews as \"not positive.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ispositive(stars):\n",
    "    if stars in [4, 5]:\n",
    "        pos = 1\n",
    "    else:\n",
    "        pos = 0\n",
    "    return pos\n",
    "\n",
    "fastFood['pos'] = fastFood.stars.apply(ispositive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>city</th>\n",
       "      <th>date</th>\n",
       "      <th>name</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>state</th>\n",
       "      <th>text</th>\n",
       "      <th>useful</th>\n",
       "      <th>word_count</th>\n",
       "      <th>text_tok</th>\n",
       "      <th>not_eng</th>\n",
       "      <th>num_non_eng</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lYv2-FaGQBhZnVxTb3Qc5Q</td>\n",
       "      <td>Las Vegas</td>\n",
       "      <td>2012-04-05 01:45:36</td>\n",
       "      <td>Wendy's</td>\n",
       "      <td>Ieq-XKnp5BrK95VuvXNouQ</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NV</td>\n",
       "      <td>PLEASE AVOID THIS PLACE.\\nstupid dude cant cou...</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>please avoid this place . stupid dude cant cou...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aZOoc-87ESqy8apJO3J-Yw</td>\n",
       "      <td>Gilbert</td>\n",
       "      <td>2017-05-28 23:01:26</td>\n",
       "      <td>Slim Chickens</td>\n",
       "      <td>ZbFJnkkPQ_fiUw0FJKzLbg</td>\n",
       "      <td>5.0</td>\n",
       "      <td>AZ</td>\n",
       "      <td>What a welcome concept in fast food.  Cute pla...</td>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>what a welcome concept in fast food . cute pla...</td>\n",
       "      <td>[jalapeño]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dKdApYVFDSNYsNOso6NYlA</td>\n",
       "      <td>Las Vegas</td>\n",
       "      <td>2017-01-07 05:43:47</td>\n",
       "      <td>White Castle</td>\n",
       "      <td>xYmddD9LEtZSoPK0x7u52w</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NV</td>\n",
       "      <td>Been wanting to try this place since everyone ...</td>\n",
       "      <td>1</td>\n",
       "      <td>116</td>\n",
       "      <td>been wanting to try this place since everyone ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KpfCj839-MPcxM8FKkW7GA</td>\n",
       "      <td>Pittsburgh</td>\n",
       "      <td>2012-10-18 19:31:19</td>\n",
       "      <td>Taco Bell</td>\n",
       "      <td>wVoXYLxYIO_JsiPQFl7E7w</td>\n",
       "      <td>3.0</td>\n",
       "      <td>PA</td>\n",
       "      <td>Stopped here because I finally had to try the ...</td>\n",
       "      <td>1</td>\n",
       "      <td>153</td>\n",
       "      <td>stopped here because i finally had to try the ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KCIVWrtbeIlLpzRJWxJz4g</td>\n",
       "      <td>Toronto</td>\n",
       "      <td>2017-07-21 17:22:22</td>\n",
       "      <td>McDonalds</td>\n",
       "      <td>ZaAVeAOF2S1PYIsg7sjJyQ</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ON</td>\n",
       "      <td>Everytime I go to this spot for ice cream, I w...</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "      <td>everytime i go to this spot for ice cream , i ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id        city                 date           name  \\\n",
       "0  lYv2-FaGQBhZnVxTb3Qc5Q   Las Vegas  2012-04-05 01:45:36        Wendy's   \n",
       "1  aZOoc-87ESqy8apJO3J-Yw     Gilbert  2017-05-28 23:01:26  Slim Chickens   \n",
       "2  dKdApYVFDSNYsNOso6NYlA   Las Vegas  2017-01-07 05:43:47   White Castle   \n",
       "3  KpfCj839-MPcxM8FKkW7GA  Pittsburgh  2012-10-18 19:31:19      Taco Bell   \n",
       "4  KCIVWrtbeIlLpzRJWxJz4g     Toronto  2017-07-21 17:22:22      McDonalds   \n",
       "\n",
       "                review_id  stars state  \\\n",
       "0  Ieq-XKnp5BrK95VuvXNouQ    1.0    NV   \n",
       "1  ZbFJnkkPQ_fiUw0FJKzLbg    5.0    AZ   \n",
       "2  xYmddD9LEtZSoPK0x7u52w    3.0    NV   \n",
       "3  wVoXYLxYIO_JsiPQFl7E7w    3.0    PA   \n",
       "4  ZaAVeAOF2S1PYIsg7sjJyQ    1.0    ON   \n",
       "\n",
       "                                                text  useful  word_count  \\\n",
       "0  PLEASE AVOID THIS PLACE.\\nstupid dude cant cou...       1          28   \n",
       "1  What a welcome concept in fast food.  Cute pla...       0          83   \n",
       "2  Been wanting to try this place since everyone ...       1         116   \n",
       "3  Stopped here because I finally had to try the ...       1         153   \n",
       "4  Everytime I go to this spot for ice cream, I w...       0          81   \n",
       "\n",
       "                                            text_tok     not_eng  num_non_eng  \\\n",
       "0  please avoid this place . stupid dude cant cou...          []            0   \n",
       "1  what a welcome concept in fast food . cute pla...  [jalapeño]            1   \n",
       "2  been wanting to try this place since everyone ...          []            0   \n",
       "3  stopped here because i finally had to try the ...          []            0   \n",
       "4  everytime i go to this spot for ice cream , i ...          []            0   \n",
       "\n",
       "   pos  \n",
       "0    0  \n",
       "1    1  \n",
       "2    0  \n",
       "3    0  \n",
       "4    0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fastFood.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = stopwords.words('english')\n",
    "sw = word_tokenize(' '.join([w for w in sw]))\n",
    "sw = sw + ['.', ',', '...', '\\'\\'', '\\\"', '``', '¡',  '{','|','||','}', '(',')']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make X and y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "REVtrain, REVtest, ytrain, ytest = train_test_split(fastFood.text_tok,fastFood.pos, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "172202    my wife and i picked up dinner at el pollo loc...\n",
       "57202     visited the restaurant recently and was quite ...\n",
       "31914     worst experience ever not the first time but m...\n",
       "1441      blaze pizza is easily one of my favorite place...\n",
       "184107    people made this place seem like the best plac...\n",
       "Name: text_tok, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "REVtest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54916,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "REVtest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change target variable\n",
    "def make_x(REVtrain, REVtest, vectorizer=None, min_df = 1, max_df = 1.0):\n",
    "    \"\"\"Create the matrix of features \"\"\"\n",
    "    if vectorizer is None:\n",
    "        print('The value of vectorizer is None ... using CountVectorizer')\n",
    "    else:\n",
    "        print('The value of vectorizer is NOT None ... using the provided vectorizer')\n",
    "    #\n",
    "    if vectorizer is None:\n",
    "        vectorizer = CountVectorizer(strip_accents = 'ascii', stop_words = sw, \n",
    "                                     min_df = min_df, max_df = max_df)\n",
    "   \n",
    "    Xtrain = vectorizer.fit_transform(REVtrain)\n",
    "    Xtrain = Xtrain.tocsc() \n",
    "    \n",
    "    Xtest = vectorizer.transform(REVtest)\n",
    "    Xtest = Xtest.tocsc()\n",
    "    \n",
    "    return Xtrain, Xtest, vectorizer \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The value of vectorizer is None ... using CountVectorizer\n"
     ]
    }
   ],
   "source": [
    "Xtrain, Xtest, vectorizer = make_x(REVtrain, REVtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of reviews:  164748\n",
      "Number of terms:  63298\n"
     ]
    }
   ],
   "source": [
    "n_rows, n_cols = Xtrain.shape\n",
    "print('Number of reviews: ', n_rows)\n",
    "print('Number of terms: ', n_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Logistic Regression Parameters: {'alpha': 5}\n",
      "Best score is 0.8430815548595431\n",
      "\n",
      "[Training Classification Report:]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.81      0.84     82065\n",
      "           1       0.82      0.89      0.86     82683\n",
      "\n",
      "   micro avg       0.85      0.85      0.85    164748\n",
      "   macro avg       0.85      0.85      0.85    164748\n",
      "weighted avg       0.85      0.85      0.85    164748\n",
      "\n",
      "Training Accuracy:  0.8490361036249302\n",
      "\n",
      "[Test Classification Report:]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.80      0.84     27281\n",
      "           1       0.82      0.89      0.85     27635\n",
      "\n",
      "   micro avg       0.84      0.84      0.84     54916\n",
      "   macro avg       0.85      0.84      0.84     54916\n",
      "weighted avg       0.85      0.84      0.84     54916\n",
      "\n",
      "Test Accuracy:  0.8441619928618254\n",
      "\n",
      "AUC:  0.9034599806275398\n",
      "\n",
      "Log loss:  0.9138543338405616\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'alpha': [0.1, 1, 5, 10, 50]}\n",
    "nb = MultinomialNB()\n",
    "nb_cv = GridSearchCV(nb, param_grid, cv = 5)\n",
    "fitted = nb_cv.fit(Xtrain, ytrain)\n",
    "print(\"Tuned Logistic Regression Parameters: {}\".format(nb_cv.best_params_)) \n",
    "print(\"Best score is {}\".format(nb_cv.best_score_))\n",
    "print('')\n",
    "\n",
    "\n",
    "ypred, yprobs = report(fitted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sineadoconnor/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/Users/sineadoconnor/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/Users/sineadoconnor/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/Users/sineadoconnor/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/Users/sineadoconnor/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/Users/sineadoconnor/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/Users/sineadoconnor/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/Users/sineadoconnor/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/Users/sineadoconnor/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/Users/sineadoconnor/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/Users/sineadoconnor/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/Users/sineadoconnor/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/Users/sineadoconnor/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/Users/sineadoconnor/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/Users/sineadoconnor/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/Users/sineadoconnor/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/Users/sineadoconnor/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/Users/sineadoconnor/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/Users/sineadoconnor/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/Users/sineadoconnor/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Logistic Regression Parameters: {'C': 0.1}\n",
      "Best score is 0.8823840046616651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sineadoconnor/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'C': [0.001, 0.1, 1, 10, 100]}\n",
    "logistic = LogisticRegression(solver = 'lbfgs')\n",
    "logreg_cv = GridSearchCV(logistic, param_grid, cv = 5)\n",
    "fitted = logreg_cv.fit(Xtrain, ytrain)\n",
    "print(\"Tuned Logistic Regression Parameters: {}\".format(logreg_cv.best_params_)) \n",
    "print(\"Best score is {}\".format(logreg_cv.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Training Classification Report:]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.89      0.90     82065\n",
      "           1       0.89      0.91      0.90     82683\n",
      "\n",
      "   micro avg       0.90      0.90      0.90    164748\n",
      "   macro avg       0.90      0.90      0.90    164748\n",
      "weighted avg       0.90      0.90      0.90    164748\n",
      "\n",
      "Training Accuracy:  0.9026938111540049\n",
      "\n",
      "[Test Classification Report:]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.88      0.88     27281\n",
      "           1       0.88      0.89      0.89     27635\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     54916\n",
      "   macro avg       0.88      0.88      0.88     54916\n",
      "weighted avg       0.88      0.88      0.88     54916\n",
      "\n",
      "Test Accuracy:  0.8844599023963872\n",
      "\n",
      "AUC:  0.9460221266203857\n",
      "\n",
      "Log loss:  0.3006074259656983\n"
     ]
    }
   ],
   "source": [
    "ypred, yprobs = report(fitted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The value of vectorizer is None ... using CountVectorizer\n"
     ]
    }
   ],
   "source": [
    "Xtrain, Xtest, vectorizer = make_x(REVtrain, REVtest, min_df = 3, max_df = 70000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of reviews:  164748\n",
      "Number of terms:  27621\n"
     ]
    }
   ],
   "source": [
    "n_rows, n_cols = Xtrain.shape\n",
    "print('Number of reviews: ', n_rows)\n",
    "print('Number of terms: ', n_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(0, 51703)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = vectorizer.get_feature_names()\n",
    "word_frequencies = np.array([Xtrain[:,i].count_nonzero() for i in range(n_cols)])\n",
    "max_doc_freq = np.max(word_frequencies)\n",
    "x_values = range(max_doc_freq)\n",
    "x_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'good'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_freq_idx = list(word_frequencies).index(max_doc_freq)\n",
    "feature_names[most_freq_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Logistic Regression Parameters: {'alpha': 1}\n",
      "Best score is 0.8425959647461577\n",
      "\n",
      "[Training Classification Report:]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.80      0.84     82065\n",
      "           1       0.82      0.90      0.86     82683\n",
      "\n",
      "   micro avg       0.85      0.85      0.85    164748\n",
      "   macro avg       0.85      0.85      0.85    164748\n",
      "weighted avg       0.85      0.85      0.85    164748\n",
      "\n",
      "Training Accuracy:  0.8498798164469371\n",
      "\n",
      "[Test Classification Report:]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.79      0.83     27281\n",
      "           1       0.81      0.89      0.85     27635\n",
      "\n",
      "   micro avg       0.84      0.84      0.84     54916\n",
      "   macro avg       0.85      0.84      0.84     54916\n",
      "weighted avg       0.85      0.84      0.84     54916\n",
      "\n",
      "Test Accuracy:  0.843943477310802\n",
      "\n",
      "AUC:  0.9027604485936052\n",
      "\n",
      "Log loss:  0.9544517849886597\n"
     ]
    }
   ],
   "source": [
    "#Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, random_state=123)\n",
    "\n",
    "param_grid = {'alpha': [0.1, 1, 5, 10, 50]}\n",
    "nb = MultinomialNB()\n",
    "nb_cv = GridSearchCV(nb, param_grid, cv = 5)\n",
    "fitted = nb_cv.fit(Xtrain, ytrain)\n",
    "print(\"Tuned Logistic Regression Parameters: {}\".format(nb_cv.best_params_)) \n",
    "print(\"Best score is {}\".format(nb_cv.best_score_))\n",
    "print('')\n",
    "\n",
    "\n",
    "ypred, yprobs = report(fitted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[21646,  5635],\n",
       "       [ 2935, 24700]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(ytest, ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive words\t     P(positive | word)\n",
      "               pulpo 0.98\n",
      "              karved 0.97\n",
      "            completo 0.97\n",
      "              mmmmmm 0.96\n",
      "             harmony 0.96\n",
      "              xavier 0.96\n",
      "             bajamar 0.96\n",
      "               yummo 0.96\n",
      "                quad 0.96\n",
      "                 pbb 0.96\n",
      "Bad words\t     P(positive | word)\n",
      "            diarrhea 0.03\n",
      "         inexcusable 0.03\n",
      "            dirtiest 0.03\n",
      "              rudest 0.02\n",
      "             slowest 0.02\n",
      "           retrained 0.02\n",
      "           cockroach 0.02\n",
      "        unacceptable 0.02\n",
      "        disrespected 0.02\n",
      "             replies 0.02\n"
     ]
    }
   ],
   "source": [
    "#identify predictive words\n",
    "\n",
    "words = np.array(feature_names)\n",
    "\n",
    "x = np.eye(Xtest.shape[1])\n",
    "probs = fitted.predict_log_proba(x)[:, 0]\n",
    "ind = np.argsort(probs)\n",
    "\n",
    "#10 most positive words\n",
    "good_words = words[ind[:10]]\n",
    "\n",
    "#10 most negative words\n",
    "bad_words = words[ind[-10:]]\n",
    "\n",
    "good_prob = probs[ind[:10]]\n",
    "bad_prob = probs[ind[-10:]]\n",
    "\n",
    "print(\"Positive words\\t     P(positive | word)\")\n",
    "for w, p in zip(good_words, good_prob):\n",
    "    print(\"{:>20}\".format(w), \"{:.2f}\".format(1 - np.exp(p)))\n",
    "    \n",
    "print(\"Bad words\\t     P(positive | word)\")\n",
    "for w, p in zip(bad_words, bad_prob):\n",
    "    print(\"{:>20}\".format(w), \"{:.2f}\".format(1 - np.exp(p)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the \"positive\" words seem strange and the negative words seem more logical.  A Google search shows Karved is a popular restaurant in Las Vegas that gets many good reviews, so it is appearing here. Perhaps words like \"xavier\" appear in few reviews that happen to be all positive.  This may be a good reason to further increase min_df later. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sineadoconnor/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/Users/sineadoconnor/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/Users/sineadoconnor/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/Users/sineadoconnor/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/Users/sineadoconnor/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/Users/sineadoconnor/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/Users/sineadoconnor/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/Users/sineadoconnor/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/Users/sineadoconnor/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/Users/sineadoconnor/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/Users/sineadoconnor/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/Users/sineadoconnor/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/Users/sineadoconnor/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/Users/sineadoconnor/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/Users/sineadoconnor/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/Users/sineadoconnor/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/Users/sineadoconnor/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/Users/sineadoconnor/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/Users/sineadoconnor/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/Users/sineadoconnor/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Logistic Regression Parameters: {'C': 0.1}\n",
      "Best score is 0.882402214290917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sineadoconnor/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "#Cross VALIDATION\n",
    "param_grid = {'C': [0.001, 0.1, 1, 10, 100]}\n",
    "logistic = LogisticRegression(solver = 'lbfgs')\n",
    "logreg_cv = GridSearchCV(logistic, param_grid, cv = 5)\n",
    "fitted = logreg_cv.fit(Xtrain, ytrain)\n",
    "print(\"Tuned Logistic Regression Parameters: {}\".format(logreg_cv.best_params_)) \n",
    "print(\"Best score is {}\".format(logreg_cv.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Training Classification Report:]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.89      0.90     82065\n",
      "           1       0.89      0.91      0.90     82683\n",
      "\n",
      "   micro avg       0.90      0.90      0.90    164748\n",
      "   macro avg       0.90      0.90      0.90    164748\n",
      "weighted avg       0.90      0.90      0.90    164748\n",
      "\n",
      "Training Accuracy:  0.9017529803093209\n",
      "\n",
      "[Test Classification Report:]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.88      0.88     27281\n",
      "           1       0.88      0.89      0.89     27635\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     54916\n",
      "   macro avg       0.88      0.88      0.88     54916\n",
      "weighted avg       0.88      0.88      0.88     54916\n",
      "\n",
      "Test Accuracy:  0.8847330468351664\n",
      "\n",
      "AUC:  0.9459625240496904\n",
      "\n",
      "Log loss:  0.3008038527214057\n"
     ]
    }
   ],
   "source": [
    "ypred, yprobs = report(fitted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[23896,  3385],\n",
       "       [ 2945, 24690]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(ytest, ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile = open('../SavedFiles/fastFood_eng_binary.pkl', 'wb')\n",
    "pickle.dump(fastFood, outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
